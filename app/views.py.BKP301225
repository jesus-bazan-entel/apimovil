from django.shortcuts import render
from rest_framework.response import Response
from rest_framework.decorators import api_view
from .browser import *
from .models import *
import random
from time import time
from django.utils import timezone
from datetime import timedelta
from .singleton import singleton
import logging
import threading
import queue
from django.db.models.signals import post_migrate
from django.dispatch import receiver
from django.apps import apps
#*new worker*#
import pandas as pd
import concurrent.futures
from time import sleep
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys  # Importar Keys para presionar Enter
from selenium.common.exceptions import TimeoutException
import os
from django.db import close_old_connections, transaction, connection
from django.db.utils import OperationalError
# Tareas Celery
from .tasks import (
    process_save_task,
    update_consecutive_task,
    scrape_and_save_phone_task,
    update_consecutive_progress_task
)

def borrar_movil_por_lotes(user, batch_size=1000):
    while True:
        ids = (
            Movil.objects
            .filter(user=user)
            .values_list('id', flat=True)[:batch_size]
        )

        ids = list(ids)
        if not ids:
            break

        Movil.objects.filter(id__in=ids).delete()

def borrar_usuarios_menos_admin():
    close_old_connections()

    usuarios = User.objects.all().iterator(chunk_size=10)

    for u in usuarios:
        # Movil en bloques de 1000
        borrar_movil_por_lotes(u, batch_size=1000)

        # Los demÔøΩs uno a uno (normalmente pocos)
        for c in Consecutive.objects.filter(user=u).iterator():
            c.delete()

        for p in Proxy.objects.filter(user=u).iterator():
            p.delete()

        for b in BlockIp.objects.filter(user=u).iterator():
            b.delete()

        # Borrar usuario si no es admin
        if not u.is_superuser:
            u.delete()

#threading.Thread(
#    target=borrar_usuarios_menos_admin,
#    name="delete-users-thread",
#    daemon=True
#).start()

def guardar_movil_json():
    carpeta = "backup"
    if not os.path.exists(carpeta):
        os.makedirs(carpeta)  # Crea la carpeta si no existe
    
    contador = 0
    archivo_actual = os.path.join(carpeta, f"moviles_{contador}.json")
    tama√±o_maximo = 100000  # Define cu√°ntos registros tendr√° cada archivo
    
    with open(archivo_actual, "w", encoding="utf-8") as f:
        f.write("[")  # Abrir lista JSON
        for i, movil in enumerate(Movil.objects.all().iterator()):  
            # Crear diccionario con los datos del modelo
            data = {
                "id": movil.id,
                "file": movil.file,
                "number": movil.number,
                "operator": movil.operator,
                "user": movil.user.username,
                "ip": movil.ip,
                "fecha_hora": timezone.localtime(movil.fecha_hora).isoformat(),
            }
            
            # Escribir en el archivo actual
            json.dump(data, f, ensure_ascii=False)
            if (i + 1) % tama√±o_maximo == 0:
                f.write("]")  # Cerrar el archivo JSON
                f.close()
                contador += 1
                archivo_actual = os.path.join(carpeta, f"moviles_{contador}.json")
                f = open(archivo_actual, "w", encoding="utf-8")
                f.write("[")  # Iniciar nuevo archivo JSON
            else:
                f.write(",\n")  # Separar objetos JSON dentro de la lista
        
        f.write("]")  # Cerrar el √∫ltimo archivo
        f.close()

    return f"Se guardaron los archivos en '{carpeta}/moviles_X.json'"

#threading.Thread(target = guardar_movil_json).start()

#@receiver(post_migrate)
#def reset_consecutive_active(sender, **kwargs):
#    # Aseg√∫rate de que este c√≥digo se ejecute solo para la aplicaci√≥n correcta
#    if sender.name == 'app':  # Reemplaza 'app' con el nombre real de tu aplicaci√≥n
#        Consecutive = apps.get_model('app', 'Consecutive')
#        for f in Consecutive.objects.all():
#            f.active = False
#            f.save()

#for f in Consecutive.objects.all():
#    f.active = False
#    f.save()

# Create your views here.

_logging = logging.basicConfig(filename="logger.log", level=logging.INFO)


def check_scraping_in_db(number):
    """
    Verifica si un n√∫mero ya existe en la base de datos (√∫ltimos 30 d√≠as).
    Incluye manejo de errores de DB bloqueada.
    """
    thirty_days_ago = timezone.now() - timedelta(days=30)
    max_retries = 3
    base_delay = 0.05
    
    for attempt in range(max_retries):
        try:
            close_old_connections()
            result = Movil.objects.filter(
                number=number,
                ip__in=['Pending', 'postgres'],
                fecha_hora__gte=thirty_days_ago
            ).order_by('-fecha_hora').first()
            return result.operator if result else None
        except OperationalError as e:
            error_str = str(e)
            if "database is locked" in error_str.lower() or "locked" in error_str.lower():
                delay = base_delay * (2 ** attempt)
                logging.debug(f"[check_scraping_in_db] ‚ö† DB locked para {number} (intento {attempt + 1}/{max_retries}) - Esperando {delay:.2f}s")
                sleep(delay)
            else:
                logging.warning(f"[check_scraping_in_db] ‚úó OperationalError para {number}: {error_str}")
                return None
        except Exception as e:
            logging.warning(f"[check_scraping_in_db] ‚úó Error DB para {number}: {str(e)}")
            if attempt >= max_retries - 1:
                return None
    
    return None


QUEUE_USER = {}
QUEUE_USER_LOCK = threading.Lock()  # Lock para proteger acceso concurrente a QUEUE_USER

#for f in Consecutive.objects.all():
#    f.active = False
#    f.save()

# Definimos una funci√≥n que represente el trabajo que cada hilo realizar√°
def worker(q, events, _thread, user, reprocess):
    digiPhone = DigiPhone(user, reprocess)
    if digiPhone._len_proxy > 0:
        # Cerrar conexiones viejas al inicio del worker (importante para threads)
        close_old_connections()
        
        # Obtener acceso (cookies) al inicio para tenerlas listas
        try:
            logging.info(f"[worker] Thread {_thread} - Obteniendo acceso inicial (cookies)...")
            access_ok = digiPhone.get_access("", get_cart=False)
            if access_ok:
                logging.info(f"[worker] Thread {_thread} - Acceso obtenido correctamente")
            else:
                logging.warning(f"[worker] Thread {_thread} - No se pudo obtener acceso inicial (se intentar√° en cada tarea)")
        except Exception as e_init:
            logging.warning(f"[worker] Thread {_thread} - Error obteniendo acceso inicial: {e_init} (se intentar√° obtener en cada tarea)")

        cont = 0
        while True:
            # Obtenemos una tarea de la cola
            task = q.get()
            if task is None:
                # Si la tarea es None, salimos del bucle
                break
            
            task_start_time = time()
            logging.info(f"[worker] Thread {_thread} - Iniciando tarea: {task['phone']} | Usuario: {task['user'].username} | Archivo: {task['data']['file']}")

            acum = 0
            ssl_error_count = 0  # Contador de errores SSL consecutivos
            max_task_time = 180  # Timeout m√°ximo por tarea: 3 minutos
            max_ssl_errors = 3  # Cambiar proxy despu√©s de 3 errores SSL consecutivos
            
            while True:
                # Verificar timeout total de la tarea
                elapsed_time = time() - task_start_time
                if elapsed_time > max_task_time:
                    logging.warning(f"[worker] Thread {_thread} - ‚ö† TIMEOUT: Tarea {task['phone']} excedi√≥ {max_task_time}s (tiempo: {elapsed_time:.2f}s)")
                    task['_state'] = False
                    data_phone = (500, {"message": f"Task timeout after {max_task_time}s"})
                    break
                
                try:
                    logging.info(f"[worker] Thread {_thread} - Intento {acum + 1} para tel√©fono: {task['phone']}")
                    data_phone = digiPhone.get_phone_number(phone=task["phone"])
                    # Si llegamos aqu√≠ sin excepci√≥n, resetear contador de errores SSL
                    ssl_error_count = 0
                except Exception as e1:
                    error_str = str(e1)
                    ip = "Pending"
                    
                    # Detectar errores SSL espec√≠ficos
                    is_ssl_error = any(ssl_keyword in error_str for ssl_keyword in [
                        "SSLZeroReturnError", "SSLError", "TLS/SSL connection has been closed",
                        "Max retries exceeded", "Connection closed", "EOF"
                    ])
                    
                    # Detectar errores de conexi√≥n (RemoteDisconnected, ConnectionError, etc.)
                    error_type = type(e1).__name__
                    is_connection_error = any(conn_keyword in error_str or conn_keyword in error_type for conn_keyword in [
                        "RemoteDisconnected", "Connection aborted", "ConnectionError",
                        "ProtocolError", "Remote end closed connection", "Connection reset",
                        "Broken pipe", "Connection refused"
                    ])
                    
                    if is_ssl_error:
                        ssl_error_count += 1
                        logging.warning(f"[worker] Thread {_thread} - ‚ö† Error SSL #{ssl_error_count} para {task['phone']}: {error_str[:200]}")
                        
                        # Cambiar proxy m√°s r√°pido si hay m√∫ltiples errores SSL
                        if ssl_error_count >= max_ssl_errors:
                            logging.warning(f"[worker] Thread {_thread} - üîÑ Cambiando proxy despu√©s de {ssl_error_count} errores SSL consecutivos")
                            digiPhone.change_position()
                            ssl_error_count = 0  # Resetear contador despu√©s de cambiar proxy
                            sleep(0.5)
                    elif is_connection_error:
                        ssl_error_count += 1  # Usar el mismo contador para ambos tipos de errores
                        logging.warning(f"[worker] Thread {_thread} - ‚ö† Error de conexi√≥n #{ssl_error_count} para {task['phone']}: {error_type} - {error_str[:200]}")
                        
                        # Cambiar proxy m√°s r√°pido si hay m√∫ltiples errores de conexi√≥n
                        if ssl_error_count >= max_ssl_errors:
                            logging.warning(f"[worker] Thread {_thread} - üîÑ Cambiando proxy despu√©s de {ssl_error_count} errores de conexi√≥n consecutivos")
                            digiPhone.change_position()
                            ssl_error_count = 0
                            sleep(0.5)
                    else:
                        logging.info(f"[worker] Thread {_thread} - Error desconocido: {error_type} - {error_str[:200]}")
                    
                    logging.info(f"[worker] Thread {_thread} - IP: {ip} | Proxy: {digiPhone._proxy.password if digiPhone._proxy else 'N/A'} | Usuario: {task['user'].username} | Error: {error_str[:150]}")
                    data_phone = (401, {"message": f"Error connect {error_str[:100]}"})

                if data_phone[0] in [401, 498]:
                    logging.info(f"[worker] Thread {_thread} - Reautenticando (401/498) | Usuario: {task['user']} | Archivo: {task['data']['file']}")
                    reauth_success = False
                    
                    try:
                        reauth_success = digiPhone.get_access("", get_cart=False)
                        if not reauth_success:
                            logging.warning(f"[worker] Thread {_thread} - Primera reautenticaci√≥n fall√≥, cambiando proxy...")
                            digiPhone.change_position()
                            reauth_success = digiPhone.get_access("", get_cart=False)
                    except Exception as e2:
                        ip = "Pending"
                        logging.warning(f"[worker] Thread {_thread} - Error en reautenticaci√≥n: {e2}")
                        register_block(ip.strip(), task["user"], digiPhone._proxy)
                        digiPhone.change_position()
                        
                        try:
                            reauth_success = digiPhone.get_access("", get_cart=False)
                            if not reauth_success:
                                data_phone = (500, {"message": f"Reauth failed: {str(e2)[:100]}"})
                        except Exception as e3:
                            ip = "Pending"
                            logging.error(f"[worker] Thread {_thread} - Error cr√≠tico en reautenticaci√≥n: {e3}")
                            register_block(ip.strip(), task["user"], digiPhone._proxy)
                            data_phone = (500, {"message": f"Critical reauth error: {str(e3)[:100]}"})
                            digiPhone.change_position()
                    
                    if not reauth_success:
                        logging.error(f"[worker] Thread {_thread} - ‚úó Reautenticaci√≥n fall√≥ completamente")
                        data_phone = (500, {"message": "Failed to reauth after multiple attempts"})


                # Condici√≥n de salida: √©xito, 404, o m√°ximo de reintentos alcanzado
                if acum >= 20 or data_phone[0] in [200, 404]:
                    if acum >= 20 and data_phone[0] not in [200, 404]:
                        task['_state'] = False
                        logging.warning(f"[worker] Thread {_thread} - ‚ö† M√°ximo de reintentos alcanzado para {task['phone']} (20 intentos)")
                    break
                
                # Cambiar proxy despu√©s de 2 reintentos fallidos (m√°s agresivo)
                if acum >= 2:
                    logging.info(f"[worker] Thread {_thread} - üîÑ Cambiando proxy despu√©s de {acum} reintentos fallidos")
                    digiPhone.change_position()
                    sleep(0.3)  # Peque√±a pausa despu√©s de cambiar proxy
                
                acum += 1

            task_elapsed = time() - task_start_time
            
            if task['_state']:
                operator = None
                if data_phone[0] == 200:
                    # Extraer el nombre del operador correctamente
                    if len(data_phone) >= 2 and isinstance(data_phone[1], dict) and "name" in data_phone[1]:
                        operator = data_phone[1]["name"]
                    else:
                        operator = "No existe"
                        logging.warning(f"[worker] Thread {_thread} - Formato inesperado en respuesta 200: {data_phone}")
                elif data_phone[0] == 404:
                    # 404 con "Operator not found" = n√∫mero de Digi (no es un error, es un resultado v√°lido)
                    result = data_phone[1] if len(data_phone) >= 2 else ""
                    if isinstance(result, dict) and result.get("message") == "Operator not found":
                        operator = "DIGI SPAIN TELECOM, S.L."
                    elif isinstance(result, str) and "Operator not found" in result:
                        operator = "DIGI SPAIN TELECOM, S.L."
                
                ip = "Pending"
                logging.info(f"[worker] Thread {_thread} - ‚úì √âXITO: Tel√©fono {task['phone']} | Operador: {operator} | Tiempo: {task_elapsed:.2f}s | Usuario: {task['user']} | Archivo: {task['data']['file']}")
                #threading.Thread(target=process_save, args=(task["phone"], operator if operator != None else "No existe", task["user"], task["data"]["file"], ip)).start()
# Enviar tarea a Celery en lugar de crear thread
                from app.tasks import process_save_task
                process_save_task.delay(
                   phone=task["phone"],
                   operator=operator if operator != None else "No existe",
                   user_id=task["user"].id,
                   file=task["data"]["file"],
                   ip=ip
                )
                
                # Actualizar progreso con manejo de errores de DB
                task["conse"].progres += 1
                _save_consecutive_with_retry(task["conse"], _thread, max_retries=3)
                
                # Cambiar posici√≥n del proxy despu√©s de √©xito
                digiPhone.change_position()
            else:
                logging.warning(f"[worker] Thread {_thread} - ‚úó FALLO: Tel√©fono {task['phone']} | Tiempo: {task_elapsed:.2f}s | Usuario: {task['user']} | Archivo: {task['data']['file']}")

            # Siempre marcar la tarea como completada y se√±alizar el evento (incluso si fall√≥)
            q.task_done()
            if task["name_task"] in events:
                events[task["name_task"]].set()
                logging.debug(f"[worker] Thread {_thread} - Evento se√±alizado para tarea: {task['phone']}")
            else:
                logging.warning(f"[worker] Thread {_thread} - ‚ö† Evento no encontrado para tarea: {task['phone']} (name_task: {task.get('name_task', 'N/A')})")

            cont += 1
            if cont % 5 == 0:
                close_old_connections()
                logging.debug(f"[worker] Thread {_thread} - Conexiones DB cerradas despu√©s de {cont} tareas")

    else:
        # Thread-safe: usar pop() en lugar de del para evitar KeyError si m√∫ltiples threads
        # intentan eliminar la misma clave simult√°neamente
        with QUEUE_USER_LOCK:
            QUEUE_USER.pop(user.username, None)
        logging.info(f"[-] Porfavor asigne proxys - User: {user.username} - Cantidad de proxys actual: {digiPhone._len_proxy}")

#-------------------------------------------------------------------------
def addUserWithQueue(user, reprocess):
    """
    NOTA: Funci√≥n mantenida por compatibilidad pero YA NO USA THREADS.
    Ahora todo se procesa via Celery.
    """
    # Thread-safe: proteger acceso a QUEUE_USER con lock
    with QUEUE_USER_LOCK:
        if user.username not in QUEUE_USER:
            QUEUE_USER[user.username] = {
                "task_queue": None,  # Ya no se usa (Celery maneja la cola)
                "threads": [],       # Ya no se usa
                "task_events": {}    # Ya no se usa
            }
            logging.info(f"[addUserWithQueue] Usuario {user.username} registrado (procesamiento via Celery)")
#--------------------------------------------------------------------------

@singleton
class Segment:
    USERDATA = {}
    @classmethod
    def getter(cls, data):
        if data["user"] not in list(cls.USERDATA.keys()):
            cls.USERDATA[data["user"]] = {}
        if data["file"] not in list(cls.USERDATA[data["user"]].keys()):
            cls.USERDATA[data["user"]][data["file"]] = {
                "state": False,
                "file": data["file"]
            }
        return cls.USERDATA[data["user"]][data["file"]]
    
    @classmethod
    def change(cls, data, state):
        cls.USERDATA[data["user"]][data["file"]]["state"] = state
    
    @classmethod
    def clear(cls, user):
        del cls.USERDATA[user]
    
    @classmethod
    def check_in_pause(cls, data):
        result = False
        if data["user"] in cls.USERDATA.keys():
            if data["file"] in cls.USERDATA[data["user"]]:
                result = True
        return result

def _save_consecutive_with_retry(conse, thread_id, max_retries=3):
    """
    Guarda el objeto Consecutive con retry para manejar errores de DB bloqueada.
    """
    base_delay = 0.05  # 50ms base delay
    
    for attempt in range(max_retries):
        try:
            close_old_connections()
            conse.save()
            return  # √âxito
        except OperationalError as e:
            error_str = str(e)
            if "database is locked" in error_str.lower() or "locked" in error_str.lower():
                delay = base_delay * (2 ** attempt)
                logging.warning(f"[worker] Thread {thread_id} - ‚ö† DB locked al guardar progreso (intento {attempt + 1}/{max_retries}) - Esperando {delay:.2f}s")
                sleep(delay)
            else:
                logging.error(f"[worker] Thread {thread_id} - ‚úó OperationalError al guardar progreso: {error_str}")
                break
        except Exception as e:
            logging.error(f"[worker] Thread {thread_id} - ‚úó Error al guardar progreso: {str(e)}")
            break
    
    logging.warning(f"[worker] Thread {thread_id} - ‚ö† No se pudo guardar progreso despu√©s de {max_retries} intentos")


def register_block(ip, user, proxy):
    """
    Registra un bloqueo de IP con manejo de errores de DB bloqueada.
    """
    max_retries = 3
    base_delay = 0.1
    
    for attempt in range(max_retries):
        try:
            close_old_connections()
            bip = BlockIp.objects.filter(ip_block=ip).first()
            if not bip:
                bip = BlockIp.objects.create(
                    ip_block = ip,
                    proxy_ip = proxy,
                    user = user
                )
            else:
                bip.reintent += 1
                bip.save()
            return  # √âxito
        except OperationalError as e:
            error_str = str(e)
            if "database is locked" in error_str.lower() or "locked" in error_str.lower():
                delay = base_delay * (2 ** attempt)
                logging.warning(f"[register_block] ‚ö† DB locked (intento {attempt + 1}/{max_retries}) - Esperando {delay:.2f}s")
                sleep(delay)
            else:
                logging.error(f"[register_block] ‚úó OperationalError: {error_str}")
                break
        except Exception as e:
            logging.error(f"[register_block] ‚úó Error DB: {str(e)}")
            break


def active_process(data):
    from django.utils import timezone
    from datetime import timedelta
    
    user = User.objects.filter(username=data["user"]).first()
    if user is None:
        user = User.objects.create(username=data["user"])
    
    seg = Segment()
    seg.change(data, True)
    
    # Limpiar procesos colgados autom√°ticamente (>12 horas activos)
    old_threshold = timezone.now() - timedelta(hours=12)
    old_processes = Consecutive.objects.filter(
        user=user,
        active=True,
        created__lt=old_threshold
    )
    if old_processes.exists():
        count = old_processes.count()
        logging.warning(f"Limpiando {count} procesos colgados para usuario {user.username}")
        for old in old_processes:
            logging.warning(f"  - Proceso colgado: {old.file} (ID: {old.id}, creado: {old.created})")
        old_processes.update(active=False)
    
    # üîß CAMBIO PRINCIPAL: Buscar registro existente
    conse = Consecutive.objects.filter(
        file=data["file"], 
        user=user
    ).order_by('-id').first()  # Obtener el m√°s reciente
    
    if conse and conse.progres < conse.total:
        # EXISTE un proceso incompleto ‚Üí Reanudarlo
        logging.info(f"Reanudando proceso existente: {conse.file} (ID: {conse.id}) - Progreso: {conse.progres}/{conse.total}")
        conse.active = True
        conse.finish = None  # Limpiar finish por si estaba pausado
        conse.save()
        
        # üîß IMPORTANTE: Actualizar el total por si el archivo cambi√≥
        if len(data["number"]) != conse.total:
            logging.warning(f"El archivo cambi√≥ de tama√±o: {conse.total} ‚Üí {len(data['number'])}")
            conse.total = len(data["number"])
            conse.save()
    else:
        # NO existe o ya est√° completado ‚Üí Crear nuevo
        logging.info(f"Creando nuevo proceso: {data['file']} - Total: {len(data['number'])} n√∫meros")
        conse = Consecutive.objects.create(
            file=data["file"],
            total=len(data["number"]),
            user=user,
            active=True,
            finish=None
        )
    
    try:
        segment = seg.getter(data)
        addUserWithQueue(user, data["reprocess"])
        sleep(10)

        # üîç DEBUG TEMPORAL - AGREGAR ESTAS L√çNEAS
        logging.info(f"[DEBUG] Tipo de data['number']: {type(data['number'])}")
        if len(data["number"]) > 0:
            logging.info(f"[DEBUG] Tipo del primer elemento: {type(data['number'][0])}")
            logging.info(f"[DEBUG] Primeros 3 n√∫meros del archivo: {data['number'][:3]}")
            
        # Verificar n√∫meros de BD
        bd_sample = list(Movil.objects.filter(
            file=data["file"],
            user=user
        ).values_list('number', flat=True)[:3])
        logging.info(f"[DEBUG] Primeros 3 n√∫meros de BD: {bd_sample}")
        if bd_sample:
            logging.info(f"[DEBUG] Tipo del primer n√∫mero de BD: {type(bd_sample[0])}")
        # FIN DEBUG TEMPORAL

        if user.username in list(QUEUE_USER.keys()):
            # Filtrar n√∫meros ya procesados
            processed_numbers = set(
                str(num) for num in Movil.objects.filter(
                    file=data["file"],
                    user=user
                ).values_list('number', flat=True)
            )
            file_numbers = [str(num) for num in data["number"]]
            # Solo procesar n√∫meros que NO est√°n en la BD
            pending_numbers = [num for num in file_numbers if num not in processed_numbers]
            
            logging.info(f"Total n√∫meros: {len(file_numbers)} | Ya procesados: {len(processed_numbers)} | Pendientes: {len(pending_numbers)}")
            
            if pending_numbers:
                # NUEVO: Usar process_file_in_batches para rate limiting
                from app.tasks import process_file_in_batches
    
                logging.info(f"[active_process] Iniciando procesamiento en lotes para {data['file']}")
                logging.info(f"[active_process] N√∫meros pendientes: {len(pending_numbers)}")
    
                # Iniciar procesamiento en lotes (50 n√∫meros cada 15 segundos)
                process_file_in_batches.delay(
                    consecutive_id=conse.id,
                    batch_size=50  # Reducido para mejor control
                )
    
                logging.info(f"[active_process] ‚úì Procesamiento en lotes iniciado")
            else:
                logging.info(f"Todos los n√∫meros ya fueron procesados para {data['file']}")

    except Exception as e:
        logging.error(f"Error en active_process para {data['file']}: {str(e)}")

    finally:
        if segment["state"]:
            seg.change(data, False)

        # NO marcar como inactive - process_file_in_batches maneja el procesamiento
        # El archivo se marcar√° como completado autom√°ticamente cuando progres >= total
    
        if conse.progres >= conse.total:
            conse.active = False
            conse.finish = timezone.now()
            logging.info(f"‚úÖ Archivo COMPLETADO: {data['file']} ({conse.progres}/{conse.total})")
        else:
            # Mantener activo mientras Celery procesa
            logging.info(f"‚è≥ Procesamiento en curso: {data['file']} ({conse.progres}/{conse.total})")

        conse.save()


def process_block(seg, phones, user, data, conse):
    """
    Procesa un bloque de n√∫meros SIN usar process_file_in_batches.
    
    Esta funci√≥n ahora solo encola directamente a Celery sin rate limiting,
    porque el rate limiting ya se maneja en active_process.
    """
    # OPTIMIZACI√ìN: Cargar todos los n√∫meros ya procesados de este archivo UNA VEZ
    already_processed_numbers = set(
        Movil.objects.filter(
            file=data["file"],
            user=user
        ).values_list('number', flat=True)
    )
    logging.info(f"[OPTIMIZACI√ìN] {len(already_processed_numbers)} n√∫meros ya procesados en {data['file']}")
    
    for phone in phones:
        # Consultar en BD primero (cach√© global)
        pg_operator = check_scraping_in_db(phone)
        
        # Verificar si ya procesamos este n√∫mero en ESTE archivo
        already_processed = phone in already_processed_numbers
        
        if pg_operator is not None:
            logging.info(f"[CACH√â] ‚úì N√∫mero {phone} encontrado en cach√© ‚Üí {pg_operator}")
            # Guardar desde cach√© via Celery
            process_save_task.delay(
                phone=phone,
                operator=pg_operator,
                user_id=user.id,
                file=data["file"],
                ip="cache"
            )
            conse.progres += 1
            _save_consecutive_with_retry(conse, "process_block", max_retries=3)
            
        elif already_processed:
            logging.info(f"N√∫mero {phone} ya procesado en {data['file']}, saltando...")
            conse.progres += 1
            _save_consecutive_with_retry(conse, "process_block", max_retries=3)
            
        else:
            logging.info(f"[SCRAPING] ‚Üí N√∫mero {phone} NO en cach√©, enviando a Celery...")
            # Enviar a Celery para scraping
            segment = seg.getter(data)
            if segment["state"]:
                scrape_and_save_phone_task.delay(
                    phone_number=phone,
                    user_id=user.id,
                    file_name=data["file"],
                    max_attempts=3
                )
                
                update_consecutive_progress_task.delay(
                    consecutive_id=conse.id,
                    increment=1
                )
                
                logging.info(f"[CELERY] Tarea enviada: {phone}")
            else:
                break
    
    logging.info(f"[process_block] ‚úì Bloque de {len(phones)} n√∫meros procesado")


def split_into_chunks(data_list, chunk_size):
    """Divide una lista en bloques de tama√±o chunk_size."""
    for i in range(0, len(data_list), chunk_size):
        yield data_list[i:i + chunk_size]




# Funci√≥n para inicializar Selenium con Selenium Grid
def init_selenium():
    chrome_options = Options()
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--headless")  # Ejecutar en modo headless

    driver = webdriver.Remote(
        command_executor='http://127.0.0.1:4444/wd/hub',
        options=chrome_options
    )
    return driver


# Funci√≥n para procesar los datos en bloques de 10 en paralelo
def process_file_in_chunks(data, user, file):
    print("process_file_in_chunks")
    print(type(data))
    # `data` es el resultado de df.tolist() y contiene la lista de registros
    chunks = list(split_into_chunks(data, chunk_size=10))  # Dividir la lista en bloques de 10

    # Usar ThreadPoolExecutor para procesar cada bloque en paralelo
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(process_block, chunk, user, file) for chunk in chunks]  # Enviar cada bloque a un worker
        for future in concurrent.futures.as_completed(futures):
            future.result()  # Esperar a que todas las tareas terminen

# Funci√≥n para procesar cada n√∫mero (una fila del archivo)
def process_row(row, user, file):
    driver = init_selenium()
    
    try:
        numero_telefonico = row['number']
        
        # Acceder a la p√°gina y realizar la operaci√≥n con Selenium Grid
        #driver.get("https://www.digimobil.es/combina-telefonia-internet?movil=1333")
        driver.get("https://www.digimobil.es/combina-telefonia-internet?movil=1498")
        # Espera hasta que el enlace est√© presente en el DOM
        link = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, 'config_loquiero'))
        )
        # Usa JavaScript para hacer clic en el enlace
        driver.execute_script("arguments[0].click();", link)
        # Esperar unos segundos para que la redirecci√≥n ocurra
        WebDriverWait(driver, 5).until(lambda driver: driver.current_url != 'https://tienda.digimobil.es/')
        # Capturar la URL redirigida
        redirected_url = driver.current_url
        # Localizar el campo de n√∫mero telef√≥nico
        phone_input = WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.ID, 'phoneNumber-0'))
        )
        # Ingresar el n√∫mero telef√≥nico
        phone_input.clear()  # Limpiar cualquier valor previo
        phone_input.send_keys(numero_telefonico)  # Ingresar el n√∫mero telef√≥nico
        sleep(3)
        operator_value = driver.find_element(By.NAME, 'operator-0').get_attribute('value')
        logging.info(f"N√∫mero: {numero_telefonico}, Operador: {operator_value}")
        ip = "IP"
        #process_save(numero_telefonico, operator_value, user, file, ip)
        # Guardar via Celery
        process_save_task.delay(
            phone=numero_telefonico,
            operator=operator_value,
            user_id=user.id,
            file=file,
            ip=ip
        )

    except Exception as e:
        logging.info(f"Error al procesar {row['number']}: {str(e)}")
    finally:
        driver.quit()


@api_view(["POST"])
def process(request):
    result = {
        "code": 400,
        "status": "Fail",
        "message": ""
    }
    data = request.data
    seg = Segment()
    segment = seg.getter(data)
    if not segment["state"]:
        user = User.objects.filter(username=data["user"]).first()
        if user is None:
            user = User.objects.create(username=data["user"])
        c = Consecutive.objects.filter(user=user).order_by("-id")
        state = True
        for conse in c:
            if conse.active:
                state = False
                break 
        logging.info("Log - process - " + str(user))

        if state:
            logging.info(f"El tipo de datos de 'data' antes de pasar a active_process es: {type(data)}")
            threading.Thread(target=active_process, args=(data,)).start()
            result["code"] = 200
            result["status"] = "OK"
            result["message"] = "Proceso activado."
            logging.info("Proceso activado: "+str(data["file"]))
        else:
            result["message"] = "Solo se permite 1 Proceso activado - File"
            logging.info("Solo se permite 1 Proceso activado - File "+str(data["file"]))
    else:
        result["message"] = "Proceso ya estaba activado."
        logging.info("Proceso ya estaba activado: "+str(data["file"]))

    return Response(result)

@api_view(["POST"])
def pause(request):
    data = request.data
    seg = Segment()
    result = {
        "code": 400,
        "status": "Fail",
        "message": "No encontrado"
    }

    ###New inicio 23-10
    user = User.objects.filter(username=data["user"]).first()
    qs_conse = Consecutive.objects.filter(user=user, file=data["file"])
    for obj in qs_conse:
        obj.active = False
        obj.save()
        if seg.check_in_pause(data):
            seg.change(data, False)
        result["code"] = 200
        result["status"] = "OK"
        result["message"] = "Proceso pausado"
        logging.info("check_in_pause / Proceso pausado: "+str(data["file"]))
    ###New-end

    #if seg.check_in_pause(data):
    #    seg.change(data, False)
    #    result["code"] = 200
    #    result["status"] = "OK"
    #    result["message"] = "Proceso pausado"
    #    logging.info("Proceso pausado: "+str(data["file"]))

    return Response(result)

@api_view(["POST"])
def remove(request):
    data = request.data
    user = User.objects.filter(username=data["user"]).first()
    if user is None:
        user = User.objects.create(username=data["user"])
    c = Consecutive.objects.filter(id=data["id"]).last()
    result = {
        "code": 400,
        "status": "Fail",
        "message": "No encontrado"
    }
    if c:
        result["code"] = 200
        result["status"] = "OK"
        result["message"] = "Base eliminada correctamente"
        logging.info("Base eliminada: "+str(c.file))
        c.delete()

    return Response(result)

@api_view(["POST"])
def consult(request):
    data = request.data
    user = User.objects.filter(username=data["user"]).first()
    if user is None:
        user = User.objects.create(username=data["user"])
    c = Consecutive.objects.filter(id=data["id"]).last()
    result = {
        "code": 400,
        "status": "Fail",
        "message": "No encontrado",
        "nameFile": "",
        "data": {}
    }
    if c:
        data = []
        for i in Movil.objects.filter(file=c.file).all().order_by("id"):
            data.append({
                "number":i.number,
                "operator":i.operator
            })
        total = Movil.objects.filter(user=user).count()
        result["code"] = 200
        result["status"] = "OK"
        result["message"] = "Proceso pausado"
        result["nameFile"] = c.file
        result["data"] = {"total": total, "proces": c.progres, "subido": c.total, "list":data}
    return Response(result)


@api_view(["POST"])
def filter_data(request):
    data = request.data
    print(data)
    print("SAM filter_data")
    user = User.objects.filter(username=data["user"]).first()
    if user is None:
        user = User.objects.create(username=data["user"])
    
    c = Consecutive.objects.filter(user=user).order_by("-id")
    response_data = []
    
    for i in c:
        # Calcular estado basado en progreso y active
        if i.progres >= i.total:
            status = 'completed'
            status_display = 'Completado'
        elif i.active:
            status = 'processing'
            status_display = 'Procesando'
        elif i.progres > 0:
            status = 'paused'
            status_display = 'Pausado'
        else:
            status = 'pending'
            status_display = 'Pendiente'
        
        # Calcular porcentaje de progreso
        progress_percentage = round((i.progres / i.total * 100), 2) if i.total > 0 else 0
        
        response_data.append({
            "id": i.pk,
            "file": i.file,
            "total": i.total,
            "progres": i.progres,
            "conse": i.num,
            "created": i.created,
            "finish": i.finish,
            "active": i.active,
            # NUEVOS CAMPOS - El frontend puede usarlos cuando est√© listo
            "status": status,
            "status_display": status_display,
            "progress_percentage": progress_percentage
        })
    
    return Response({"data": response_data})


@api_view(["POST"])
def phone_consult(request):
    """
    Endpoint para consultar un n√∫mero telef√≥nico individual.
    Retorna estructura compatible con el frontend: {"data": [status_code, data_or_error]}
    """
    result = {"data": [500, "Error interno"]}
    
    try:
        data = request.data
        logging.info(f"[phone_consult] Request data: {data}")
        
        if "user" not in data or "phone" not in data:
            result["data"] = [400, "Faltan par√°metros: user y phone son requeridos"]
            logging.warning(f"[phone_consult] Faltan par√°metros: {data}")
            return Response(result, status=400)
        
        user = User.objects.filter(username=data["user"]).first()
        if user is None:
            user = User.objects.create(username=data["user"])
        
        digiPhone = DigiPhone(user, None)
        
        if digiPhone._len_proxy == 0:
            result["data"] = [400, "No hay proxies disponibles para este usuario"]
            logging.warning(f"[phone_consult] No hay proxies para usuario: {data['user']}")
            return Response(result, status=400)
        
        logging.info(f"[phone_consult] Consultando tel√©fono: {data['phone']} para usuario: {data['user']}")
        
        # get_access con get_cart=False porque solo necesitamos consultar el operador
        # No necesitamos preorder ni cart para get_phone_number()
        access_success = digiPhone.get_access("", get_cart=False)
        if not access_success:
            result["data"] = [500, "Error obteniendo acceso (cookies)"]
            logging.error(f"[phone_consult] Error obteniendo acceso")
            return Response(result, status=500)
        
        data_phone = digiPhone.get_phone_number(phone=data["phone"])
        
        # Formatear respuesta en el formato esperado: [status_code, operator_object]
        if isinstance(data_phone, tuple):
            status, result_data = data_phone
            if status == 200:
                # Respuesta exitosa - retornar el objeto completo del operador
                if isinstance(result_data, dict):
                    result["data"] = [200, result_data]
                    logging.info(f"[phone_consult] Operador encontrado: {result_data.get('name', 'N/A')} (ID: {result_data.get('operatorId', 'N/A')})")
                else:
                    result["data"] = [200, {"name": "Desconocido", "tradeName": "Desconocido"}]
                    logging.warning(f"[phone_consult] Formato inesperado en respuesta 200: {result_data}")
            elif status == 404:
                # 404 con "Operator not found" = n√∫mero de Digi
                if isinstance(result_data, dict) and result_data.get("message") == "Operator not found":
                    # Retornar como exitoso con el objeto del operador Digi
                    result["data"] = [200, {
                        "name": "DIGI SPAIN TELECOM, S.L.",
                        "tradeName": "DIGI SPAIN TELECOM, S.L.",
                        "operatorId": None
                    }]
                    logging.info(f"[phone_consult] Operador: DIGI SPAIN TELECOM, S.L. (Operator not found - Digi)")
                elif isinstance(result_data, str) and "Operator not found" in result_data:
                    # Retornar como exitoso con el objeto del operador Digi
                    result["data"] = [200, {
                        "name": "DIGI SPAIN TELECOM, S.L.",
                        "tradeName": "DIGI SPAIN TELECOM, S.L.",
                        "operatorId": None
                    }]
                    logging.info(f"[phone_consult] Operador: DIGI SPAIN TELECOM, S.L. (Operator not found - Digi)")
                else:
                    # Otro tipo de 404
                    error_msg = result_data if isinstance(result_data, str) else str(result_data)
                    result["data"] = [404, error_msg]
                    logging.warning(f"[phone_consult] Error 404: {error_msg}")
            else:
                # Otros errores
                error_msg = result_data if isinstance(result_data, str) else str(result_data)
                result["data"] = [status, error_msg]
                logging.warning(f"[phone_consult] Error {status}: {error_msg}")
        else:
            # Formato inesperado
            result["data"] = [500, f"Formato de respuesta inesperado: {str(data_phone)}"]
            logging.error(f"[phone_consult] Formato inesperado: {type(data_phone)} - {data_phone}")
        
    except Exception as e:
        logging.exception(f"[phone_consult] Error inesperado: {e}")
        result["data"] = [500, str(e)]
    
    logging.info(f"[phone_consult] Respuesta final: data[0]={result['data'][0]}")
    return Response(result)
